<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title>Gold and Rabbit&#39;s Blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="having fun coding">
<meta property="og:type" content="website">
<meta property="og:title" content="Gold and Rabbit&#39;s Blog">
<meta property="og:url" content="http://example.com/page/2/index.html">
<meta property="og:site_name" content="Gold and Rabbit&#39;s Blog">
<meta property="og:description" content="having fun coding">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="Gold and Rabbit">
<meta property="article:tag" content="Recommending System">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="Gold and Rabbit&#39;s Blog" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  
<link rel="stylesheet" href="/css/style.css">

<meta name="generator" content="Hexo 5.1.1"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Gold and Rabbit&#39;s Blog</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://example.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-Status as a Service" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/04/13/Status%20as%20a%20Service/" class="article-date">
  <time datetime="2020-04-13T12:13:00.000Z" itemprop="datePublished">2020-04-13</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Reading/">Reading</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/04/13/Status%20as%20a%20Service/">Status as a Service</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
      	<!-- Table of Contents -->
		
        <hr>
<h2 id="Social-network-Status-as-a-Service-社交网络：地位即服务"><a href="#Social-network-Status-as-a-Service-社交网络：地位即服务" class="headerlink" title="Social network: Status as a Service 社交网络：地位即服务"></a>Social network: Status as a Service 社交网络：地位即服务</h2><p>本文对社交网络进行研究，解释以下几个问题(问题之间并不互斥，说的是同一种观点)</p>
<ol>
<li>为什么社交软件总会过时;</li>
<li>为什么有些社交软件会成功，有些社交软件会失败;</li>
<li>抛开其他所有因素，单从社会资本/社会地位这个角度分析，如何解释问题1和问题2；</li>
</ol>
<hr>
<h2 id="Status-Seeking-Monkeys-人是追求社会地位的猴子"><a href="#Status-Seeking-Monkeys-人是追求社会地位的猴子" class="headerlink" title="Status-Seeking Monkeys 人是追求社会地位的猴子"></a>Status-Seeking Monkeys 人是追求社会地位的猴子</h2><center>
<font size="5" color="red" ><i>"It is a truth universally acknowledged, that a person in possession of little fortune, must be in want of more social capital."</i></font>
</center>

<p>一条真理：穷人、没钱的人，总是无形中更多地需要一点社会地位。</p>
<p>Let’s begin with two principles:  </p>
<ul>
<li><strong>People are status-seeking monkeys.</strong> 人是什么？人是追求社会地位的猴子.</li>
<li><strong>People seek out the most efficient path to maximizing social capital.</strong> 人，这种追求社会地位的猴子，总是在沿着最高效的路径来追求社会地位。</li>
</ul>
<p>In the past few years, much progress has been made analyzing Software as a Service (SaaS) businesses. Not as much has been made on social networks. Analysis of social networks still strikes me as being like economic growth theory long before Paul Romer’s paper on endogenous technological change. However, we can start to demystify social networks if we also think of them as SaaS businesses, but instead of software, they provide status. This post is a deep dive into what I refer to as Status as a Service (StaaS) businesses.   </p>
<p>过去几年中，“软件即服务”（SaaS）这种思想盛行，因此涉及到分析社交网络的问题，可以通过这种框架来思考。但是社交网络（想想facebook/twitter/instgram/snapcat/微博/微信）最本质的地方：提供一种人的地位。这种提出的思路被称为“地位即服务”（StaaS）。</p>
<hr>
<h2 id="Traditional-Network-Effects-Model-of-Social-Networks-社交网络的传统网络效应模型"><a href="#Traditional-Network-Effects-Model-of-Social-Networks-社交网络的传统网络效应模型" class="headerlink" title="Traditional Network Effects Model of Social Networks 社交网络的传统网络效应模型"></a>Traditional Network Effects Model of Social Networks 社交网络的传统网络效应模型</h2><p>One of the fundamental lessons of successful social networks is that they must first appeal to people when they have few users. Typically this is done through some form of single-user utility. This is the classic cold start problem of social.  </p>
<p>经典社交冷启动：成功的社交网络，有个最基本的经验，就是当刚开始没有用户的时候，必须吸引住人。典型做法是：以单个用户（利用软件）完成某个实用功能。</p>
<p>The second fundamental lessons is that social networks must have strong network effects so that as more and more users come aboard, the network enters a positive flywheel of growth, a compounding value from positive network effects that leads to hockey stick growth that puts dollar signs in the eyes of investors and employees alike. </p>
<center>
<font size="5" color="red"><i>"Come for the tool, stay for the network."</i></font>
</center>

<p>wrote Chris Dixon, in perhaps the most memorable maxim for how this works.  </p>
<p>具备强网络效应：让更多的用户入坑。进来网络的人，好比启动了一个高速转动的飞轮，然后由于积极网络效应带来的综合价值，导致投资人和员工眼里满满都是人民币。有句话叫做“为工具而来，为网络而留”，就是说的这个意思。</p>
<p>Even before social networks, we had Metcalfe’s Law on telecommunications networks: The value of a telecommunications network is proportional to the square of the number of connected users of the system (n^2). This ported over to social networks cleanly. It is intuitive, and it includes that tantalizing math formula that explains why growth curves for social networks bends up sharply at the ankle of the classic growth S-curve.  </p>
<p>在互联网社交软件出现之前，就有个叫做梅特卡夫定律，本意说的是电信网络（就是打电话），很早就是说过这个本质。电信用户的价值，正比于用户数量的平方。</p>
<p>But dig deeper and many many questions remain. Why do some large social networks suddenly fade away, or lose out to new tiny networks? Why do some new social networks with great single-player tools fail to transform into networks, while others with seemingly frivolous purposes make the leap? Why do some networks sometimes lose value when they add more users? What determines why different networks stall out at different user base sizes? Why do some networks cross international borders easily while others stay locked within specific countries? Why, if Metcalfe’s Law holds, do many of Facebook’s clones of other social network features fail, while some succeed, like Instagram Stories?  </p>
<p>但是传统网络效应模型有很多不能解释的问题。  </p>
<ol>
<li>为什么有些大型的社交网络突然留不住用户？或者被一些新出现的小型社交网络替代？</li>
<li>为什么有些社交网络工具不能形成网络效应，但是另一些看起来没用的却实现了质变？</li>
<li>为什么有些社交网络能够全世界都很流行，然而另一些却只能在本国流行出不去？</li>
<li>Facebook克隆（抄袭？）了很多社交软件的功能，但是一些失败了，有一些成功了（例如Instagram Stories）？</li>
</ol>
<hr>
<h2 id="Utility-vs-Social-Capital-Framework-实用性-v-s-社会资本"><a href="#Utility-vs-Social-Capital-Framework-实用性-v-s-社会资本" class="headerlink" title="Utility vs. Social Capital Framework 实用性 v.s. 社会资本"></a>Utility vs. Social Capital Framework 实用性 v.s. 社会资本</h2><p>事实上，社交网络应该用三跳轴线去解读。但是“娱乐性”这个维度比较复杂，简化起见采用两轴解释。  </p>
<p>A social network like Facebook allows me to reach lots of people I would otherwise have a harder time tracking down, and that is useful. A messaging app like WhatsApp allows me to communicate with people all over the world without paying texting or incremental data fees, which is useful. Quora and Reddit and Discord and most every social network offer some forms of utility.  </p>
<p>facebook：社交网络的实用性不难理解。例如Facebook能让我们接触到很多人，没有它就完全接触不到。whatsapp支持即时通讯，不用在额外花发短信钱。Quora，Reddit，Discord同理也是具备某种形式的实用性。</p>
<p>The other axis is, for a lack of a more precise term, the social capital axis, or the status axis. Can I use the social network to accumulate social capital? What forms? How is it measured? And how do I earn that status?   </p>
<p>此外谈谈社会地位这根轴。这根轴没有精确的定义。可以叫社会资本，也可以叫社会地位。那么，人可以利用社交网络积累社会资本吗？以什么形式积累社会资本？如何去衡量一个人积累了多少社会资本？另外如何通过社交网络获得社会地位？</p>
<p>The creation of a successful status game is so mysterious that it often smacks of alchemy.  </p>
<p>创造成功地位的这种局（这种游戏），实在是太迷，和炼丹差不多。</p>
<p>With the rise of Instagram, with its focus on photos and filters, and Snapchat, with its ephemeral messaging, and Vine, with its 6-second video limit, for a while there was a thought that new social networks would be built on some new modality of communications. That’s a piece of it, but it’s not the complete picture, and not for the reasons many people think, which is why we have seen a whole bunch of strange failed experiments in just about every odd combinations of features and filters and artificial constraints in how we communicate with each other through our phones. Remember Facebook’s Snapchat competitor Slingshot, in which you had to unlock any messages you received by responding with a message? It felt like product design by mad libs.  </p>
<p>社交网络的崛起， Instagram专注照片和滤镜的 ，Snapchat专注阅后即焚的 。人们一度认为新的社交网络必须建立在新的通讯形态上。但这是管中窥豹，而且搞错了因果。这也就是为什么我们会在手机通讯领域，看到一大堆失败的奇怪实验品，几乎涵盖了所有的奇特功能、滤镜特效和人为约束。还记得为了与 Snapchat 竞争，Facebook 推出的 Slingshot 吗？你必须通过回复一条消息来解锁你刚收到的消息。</p>
<p>When modeling how successful social networks create a status game worth playing, a useful metaphor is one of the trendiest technologies: cryptocurrency.  </p>
<p>如何认识：社交网络创造一种社会地位（这种看起来很迷很迷的局）用什么样的视角，用什么样的建模思路去解读呢。作者脑洞大开：用当前最时髦的技术之一：加密货币。作者认为，这种创造社会地位的玩法，和加密货币有很强的内在联系。  </p>
<hr>
<h2 id="Social-Networks-as-ICO’s-社交网络是一种ICO行为"><a href="#Social-Networks-as-ICO’s-社交网络是一种ICO行为" class="headerlink" title="Social Networks as ICO’s 社交网络是一种ICO行为"></a>Social Networks as ICO’s 社交网络是一种ICO行为</h2><p>ICO，Initial Coin Offering，首次币发行，是区块链行业术语，是一种为加密数字货币/区块链项目筹措资金的常用方式，早期参与者可以从中获得初始产生的加密数字货币作为回报。<br>How is a new social network analogous to an ICO? 社交网络和ICO有啥关系？  </p>
<ol>
<li>Each new social network issues a new form of social capital, a token. 每个社交网络都会发行一种新形态的社会资本，一种代币。</li>
<li>You must show proof of work to earn the token. 你必须证明自己的工作量，才能获得代币。  </li>
<li>Over time it becomes harder and harder to mine new tokens on each social network, creating built-in scarcity. 随着时间推移，每个社交网络上，挖掘新代币变得越来越难，从而创造出一种内在的稀缺性。  </li>
<li>Many people, especially older folks, scoff at both social networks and cryptocurrencies. 很多人，尤其是老人，同时看不起社交网络和加密货币。（很有意思的论据有木有）  </li>
</ol>
<p>然后作者分享了一个案例，又一次在朋友家，他朋友高中的女儿在楼上叮呤咣啷，声音吵杂，嘻嘻哈哈，不时地跺脚，还放音乐。一问咋回事。拍了Musical.ly的视频。排练非常卖力，累的上气不接下气，满脸是汗水，拍了很多遍。这是什么？请把她们的行为理解成一种工作量证明。Proof of work。  </p>
<p>status games of adults are already well covered by the existing media, from literature to film. Children’s status games, once familiar to us, begin to fade from our memory as time passes, and its modern forms have been drastically altered by social media. </p>
<p>然后作者就思考了成年人的证明社会地位的游戏，现有主流媒体把这种成年人证明社会地位的游戏都已经做的烂大街了，不管是文字还是电影。（我理解这句话。想想刷到的抖音、想想自己的朋友圈，里面一切成年人带有一点装逼的情节（装逼这里不贬义）、或者彰显自己才华、或者自己特殊才艺、特殊兴趣爱好的情节、秀自己身材样貌、搞笑天赋、科研实力、旅游过程中的心灵体验、宗教信仰、美食鸡汤，仔细想想这个是不是符合每一条，几乎每一条都是一种status）。但是儿童地位的游戏，我们曾经是熟知的那些，已经渐渐消失了。（想想我小时候有四驱车、玩具枪、整箱整箱的玩具、小霸王游戏机、地沟油零食、甚至是老师发的小红花，这些不都是小时候证明我们自己“地位”的东西吗，我们小时候就是每天都在玩这种“地位”的游戏）。但是现代的社会形态和科技形态，已经使得这种形式通过不同的社交媒体发生了变化。比如王者农药的皮肤。这不就是现在儿童的“地位”吗？</p>
<p>Other examples abound. Perhaps you’ve read a long and thoughtful response by a random person on Quora or Reddit, or watched YouTube vloggers publishing night after night, or heard about popular Vine stars living in houses together, helping each other shoot and edit 6-second videos. While you can outsource Bitcoin mining to a computer, people still mine for social capital on social networks largely through their own blood, sweat, and tears. </p>
<p>继续拓宽思维思维，还有各种五光十色、光怪陆离、屡见不鲜的社会资本/社会地位追求形式。比如Quora或者Reddit上的帖子。（想想知乎上：谢邀。人在美国，刚下飞机，国内Top2高效，cs在读，人工智能劝退，熟人太多，匿了匿了。c++ primer 强势审校。）youtube上vlog博主连夜做视频。这个时代，你可以把挖矿的工作交给一台计算机，但是人们会乐此不疲，呕心沥血的追求自己的社会资本。</p>
<p>Perhaps, if you’ve spent time around today’s youth, you’ve watched with a mixture of horror and fascination as a teen snaps dozens of selfies before publishing the most flattering one to Instagram, only to pull it down if it doesn’t accumulate enough likes within the first hour. It’s another example of proof of work, or at least vigorous market research. </p>
<p>你如果和年轻人相处过一段时间，你会发现。年轻人是一种恐惧和着迷的集合体。他们会拍10张自拍然后把自己最满意的发在instgram上；如果一不小心没人点赞，他们就偷偷删掉。（捂脸。我真干过这种事）这是“工作量证明”的另一个例子。</p>
<p>If you’ve ever joined one of these social networks early enough, you know that, on a relative basis, getting ahead of others in terms of social capital (followers, likes, etc.) is easier in the early days. Some people who were featured on recommended follower lists in the early days of Twitter have follower counts in the 7-figures, just as early masters of Musical.ly and Vine were accumulated massive and compounding follower counts. The more people who follow you, the more followers you gain because of leaderboards and recommended follower algorithms and other such common discovery mechanisms.  </p>
<p>另外社交网络这玩意有个特点，越早加入的人，社交资本（比如说量化成粉丝量、点赞数量）就更容易领先他人。这是由于目前的分发机制：不管是人工排行榜、或者推荐算法，都会基于历史统计决策。想想电商运营选品还是机器学习工程师抽统计特征，都是会引入历史统计特征。</p>
<p>It’s true that as more people join a network, more social capital is up for grabs in the aggregate. However, in general, if you come to a social network later, unless you bring incredible exogenous social capital (Taylor Swift can join any social network on the planet and collect a massive following immediately), the competition for attention is going to be more intense than it was in the beginning. Everyone has more of an understanding of how the game works so the competition is stiffer.  </p>
<p>这就带来一个问题：来的越晚的人，在自然情况下入局就更难（火起来越难）。我说下个人理解：回顾想想字节跳动长久发展的核心策略，是不是坚持一直对新的创造者人为的倾斜流量？我认为是的。这不就是一种典型通过流量调控达到的整个生态持久繁荣的目的的case吗？脑洞再开一下，上升到经济学的角度来看，个人感觉这就好比早期的自由市场，靠看不见的手调控整个生态，但是为了长久发展，政府的宏观调控使得整个经济形态健康发展而不会出现过于严重的垄断。</p>
<p>但是有一种例外，叫做外生社会资本（exogenous social captial），假如现在有个新的社交平台火起来。不管你多早加入，你也无法改变一个事实，泰勒多晚加入她都比你影响力大多了。  </p>
<hr>
<h2 id="Why-Proof-of-Work-Matters-为什么社交网络需要工作量证明"><a href="#Why-Proof-of-Work-Matters-为什么社交网络需要工作量证明" class="headerlink" title="Why Proof of Work Matters? 为什么社交网络需要工作量证明?"></a>Why Proof of Work Matters? 为什么社交网络需要工作量证明?</h2><p>As with cryptocurrency, if it were so easy, it wouldn’t be worth anything. Value is tied to scarcity, and scarcity on social networks derives from proof of work. Status isn’t worth much if there’s no skill and effort required to mine it. It’s not that a social network that makes it easy for lots of users to perform well can’t be a useful one, but competition for relative status still motivates humans. Recall our first tenet: humans are status-seeking monkeys. Status is a relative ladder. By definition, if everyone can achieve a certain type of status, it’s no status at all, it’s a participation trophy.  </p>
<p>接下来请以一个社交网络app的设计者的出发点来思考问题，为什么需要负担很重的工作量证明呢？人们如果要最大化社会资本，不应该弄简单点吗？和加密货币原理一样，容易实现的东西就是没有价值。价值就是稀缺性，社交网络的稀缺性就是工作量证明。如果不需要用户掌握任何技能，付出努力，这种地位也就自然不值钱。这里注意，这不是说社交网络让用户用起来简单点是完全没用的。但是人们会为相对地位而竞争：人是追求社会地位的猴子。社会地位是什么？是一种相对性的等级阶梯。皇帝还是平民，富人还是穷人，老师还是学生。在这种定义情况下，试想一下如果每个人都能达到某种地位，那也就没有地位这么一个概念了，因为每个人都有了，这种地位就变成了人手一份的“参与奖”没有任何意义了。  </p>
<p>Twitter启动Favstar和Favrd两个功能，写出全球最受欢迎推文的人，获得奖牌，瞬间让更多优质内容浮出水面。  </p>
<p>Thirst for status is potential energy. It is the lifeblood of a Status as a Service business. To succeed at carving out unique space in the market, social networks offer their own unique form of status token, earned through some distinctive proof of work.<br>对地位的渴望，是一股潜在能量。它是“地位即服务”的业务命脉。要想开辟一个独特的市场，社交网络必须提供一种独特的地位的代币。同时，要想争取这些代币，必须付出独特的工作量证明。  </p>
<p>Conversely, let’s look at something like Prisma, a photo filter app which tried to pivot to become a social network. Prisma surged in popularity upon launch by making it trivial to turn one of your photos into a fine art painting with one of its many neural-network-powered filters. It worked well. Too well. Since almost any photo could, with one-click, be turned into a gorgeous painting, no single photo really stands out. The star is the filter, not the user, and so it didn’t really make sense to follow any one person over any other person. Without that element of skill, no framework for a status game or skill-based network existed. It was a utility that failed at becoming a Status as a Service business. In contrast, while Instagram filters, in its earliest days, improved upon the somewhat limited quality of smartphone photos at the time, the quality of those photos still depended for the most part on the photographer. The composition, the selection of subject matter, these still derived from the photographer’s craft, and no filter could elevate a poor photo into a masterpiece.  </p>
<p>看一个反例，Prisma。这个照片滤镜app曾经尝试转型为社交网络app。刚出的时候非常受欢迎，因为用神经网络添加滤镜效果让你的照片变成精美的艺术品。但是它真的是太好用了，过于好用了。因为每一张照片只需要点击一下就变成漂亮的艺术品。所以没有照片能脱颖而出。这款软件的主角实质上是这个强大的滤镜功能，而不是用户，这就太喧宾夺主了。大家也很少care其他人。因为大家水平都差不多。  </p>
<p>So, to answer an earlier question about how a new social network takes hold, let’s add this: a new Status as a Service business must devise some proof of work that depends on some actual skill to differentiate among users. If it does, then it creates, like an ICO, some new form of social capital currency of value to those users.   </p>
<p>因此一个全新的社交网络，该如何站稳脚跟？对于前面提到的这个问题，让我们再来补充一点：全新的 “社会地位即服务” 业务，必须设计出独特的工作量证明机制，它将要求用户们展示出真实技能。社交网络将以此为依据，来划分用户。如果社交网络能做到这一点，它就能像 ICO 一样，为这些用户创造一种全新的社会资本货币。</p>
<hr>
<h2 id="Facebook’s-Original-Proof-of-Work-Facebook的最早工作量体现"><a href="#Facebook’s-Original-Proof-of-Work-Facebook的最早工作量体现" class="headerlink" title="Facebook’s Original Proof of Work  Facebook的最早工作量体现"></a>Facebook’s Original Proof of Work  Facebook的最早工作量体现</h2><p>In fact, Facebook launched with one of the most famous proof of work hurdles in the world: you had to be a student at Harvard. By requiring a harvard.edu email address, Facebook drafted off of one of the most elite cultural filters in the world. It’s hard to think of many more powerful slingshots of elitism. By rolling out, first to Ivy League schools, then to colleges in general, Facebook scaled while maintaining a narrow age dispersion and exclusivity based around educational credentials. Layer that on top of the broader social status game of stalking attractive members of the other sex that animates much of college life and Facebook was a service that tapped into reserves of some of the most heated social capital competitions in the world.  </p>
<p>Facebook的最早工作量证明：你必须是哈佛学生。用harvard.edu邮箱注册。然后逐渐铺开到常春藤学校，然后是全美所有大学。FB保持用户年龄分布比较集中，且学历排他。然后，更能调动大学生积极性的地位游戏是 “stalk” 其他有吸引力的异性同学。加上前面两点，Facebook 成功利用了世界上最激烈的社会资本竞争。  </p>
<hr>
<h2 id="Social-Capital-ROI-关注社会资本回报率"><a href="#Social-Capital-ROI-关注社会资本回报率" class="headerlink" title="Social Capital ROI 关注社会资本回报率"></a>Social Capital ROI 关注社会资本回报率</h2><p>If a person posts something interesting to a platform, how quickly do they gain likes and comments and reactions and followers? The second tenet is that people seek out the most efficient path to maximize their social capital. To do so, they must have a sense for how different strategies vary in effectiveness. Most humans seem to excel at this. </p>
<p>思考一个问题。如果一个人在社交平台发布了一条内容，他获得点赞评论关注的速度有多快？多快其实还不是重点，应该思考的是，人们有多大程度上的意愿，要快速的追求社会资本。引出第二个原则：人们在追求社会地位的时候，一定会追求最有效的途径，使得最大化社会资本。怎么才是最有效呢?   </p>
<p>The gradient of your network’s social capital ROI can often govern your market share among different demographics. Young girls flocked to Musical.ly in its early days because they were uniquely good at the lip synch dance routine videos that were its bread and butter. In this age of neverending notifications, heavy social media users are hyper aware of differing status ROI among the apps they use.    </p>
<p>社交网络中，社会资本回报率的梯度，往往可以主导你在不同人群中的市场份额。比如，年轻女孩子特别擅长对嘴舞蹈表演，所以在 Musical.ly 的早期，她们就蜂拥而至，而这些表演视频，恰恰是 Musical.ly 赖以生存的饭碗。在这个时代，社交媒体的通知推送，永无休止。重度用户都非常清楚，这些应用中，哪些有更高的回报率，能更有效地获取社会地位。</p>
<p>TikTok is an interesting new player in social media because its default feed, For You, relies on a machine learning algorithm to determine what each user sees; the feed of content from by creators you follow, in contrast, is hidden one pane over. If you are new to TikTok and have just uploaded a great video, the selection algorithm promises to distribute your post much more quickly than if you were on sharing it on a network that relies on the size of your following, which most people have to build up over a long period of time. Conversely, if you come up with one great video but the rest of your work is mediocre, you can’t count on continued distribution on TikTok since your followers live mostly in a feed driven by the TikTok algorithm, not their follow graph.   </p>
<p>TikTok是一个新的有趣社交媒体，因为它默认就是 “推荐” 页。“推荐” 页会依赖机器学习算法来确定每个用户看到的内容。相比之下，你关注的创作者所提供的内容，会被藏在旁边另一个页面上。如果你是抖音新人，并刚上传了一个精彩的视频，那么推荐算法可以更快地分发你的帖子。而如果只靠自己在社交网络圈分享，大多数人都必须花很长一段时间，才能构建起足够大的圈子。但反过来说，如果你只有一个精彩的视频，而其余的作品都很平庸，你不能指望抖音会继续帮你分发内容。因为，你的关注者主要看的，是由抖音的推荐算法驱动的信息流，而不是由他们的关注图谱驱动的信息流。</p>
<p>The result is a feedback loop that is much more tightly wound that that of other social networks, both in the positive and negative direction. Theoretically, if the algorithm is accurate, the content in your feed should correlate most closely to quality of the work and its alignment with your personal interests rather than the drawing from the work of accounts you follow. At a time when Bytedance is spending tens (hundreds?) of millions of marketing dollars in a bid to acquire users in international markets, the rapid ROI on new creators’ work is a helpful quality in ensuring they stick around.  </p>
<p>这样做的结果是：抖音的反馈链路比其他社交网络更环环紧扣，无论是正反馈还是负反馈。从理论上讲，如果推荐算法是准确的，你的信息流里出现的内容，会和内容的质量，以及你的个人兴趣关系最大，而不会和你所关注的帐户产生太大关系。眼下，字节跳动公司在市场营销上花费数千万 (数亿？) 美金，以获取国际市场上的用户。作品见效快，回报率高，这是确保新创作者能持续呆下去的法宝。</p>
<p>This development is interesting for another reason: graph-based social capital allocation mechanisms can suffer from runaway winner-take-all effects. In essence, some networks reward those who gain a lot of followers early on with so much added exposure that they continue to gain more followers than other users, regardless of whether they’ve earned it through the quality of their posts. One hypothesis on why social networks tend to lose heat at scale is that this type of old money can’t be cleared out, and new money loses the incentive to play the game.  </p>
<p>社交网络的这种演化过程很有意思，还有另一个原因：基于 “社交图谱” 的社会资本分配机制，可能会因 ”赢家通吃” 效应而失控。一些社交网络，从本质上看，给那些在早期就获得大量关注者的人，奖励了过多的曝光度；以至于之后，无论帖子质量如何，他们都可以比其他用户获得更多的关注者。为什么随着社交网络规模的变大，会出现 “蒸发冷却效应”？一个假设是，如果老贵族 (old money) 不走，新贵族 (new money) 就会失去玩游戏的动力。</p>
<p>The same way many social networks track keystone metrics like time to X followers, they should track the ROI on posts for new users. It’s likely a leading metric that governs retention or churn. It’s useful as an investor, or even as a curious onlooker to test a social networks by posting varied content from test accounts to gauge the efficiency and fairness of the distribution algorithm.   </p>
<p>很多社交网络都会跟踪关键指标。比如，获得 X 个关注者需要花多少时间。同样，它们也应该跟踪新用户帖子的回报率 (ROI)。这可能是控制留存率、流失率的一个主要指标。作为一个投资者，甚至是一个好奇的旁观者，可以通过从测试账户发布各种内容，来衡量社交网络分发算法的效率性和公平性，这非常有价值。</p>
<p>Whatever the mechanisms, social networks must devote a lot of resources to market making between content and the right audience for that content so that users feel sufficient return on their work. Distribution is king, even when, or especially when it allocates social capital.   </p>
<p>无论采用何种机制，社交网络都必须投入大量的资源，来撮合市场上的内容及其正确受众，让用户感受到努力皆有回报。分发为王，哪怕 (或者说尤其) 是在分发社会资本时。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2020/04/13/Status%20as%20a%20Service/" data-id="ckjuw1zeg001znbdl8clufsa0" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-Git Tutorial" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/04/05/Git%20Tutorial/" class="article-date">
  <time datetime="2020-04-05T14:56:00.000Z" itemprop="datePublished">2020-04-05</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Programming-Data/">Programming & Data</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/04/05/Git%20Tutorial/">Git Tutorial</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
      	<!-- Table of Contents -->
		
        <hr>
<h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><p>执行</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh-keygen -t rsa -C &quot;github的邮箱地址&quot;</span><br></pre></td></tr></table></figure>
<p>一路enter<br>（通过ls查看～/.ssh下面的所有内容查看）</p>
<p>将刚刚创建的ssh keys添加到github中</p>
<ol>
<li>利用gedit/cat命令，查看id_rsa.pub的内容</li>
<li>在GitHub中，依次点击Settings -&gt; SSH Keys -&gt; Add SSH Key，将id_rsa.pub文件中的字符串复制进去，注意字符串中没有换行和空格。</li>
</ol>
<p>再次检查SSH连接情况(在～/.ssh目录下):<br>输入如下命令</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh -T git@github.com</span><br></pre></td></tr></table></figure>

<p>看到如下所示，则表示添加成功</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Hi 你的用户名! You’ve successfully authenticated, but GitHub does <span class="keyword">not</span> provide shell access.</span><br></pre></td></tr></table></figure>

<p>即利用自己的用户名和email地址配置git</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git config --<span class="keyword">global</span> user.name <span class="string">&quot;你的github用户名&quot;</span></span><br><span class="line">git config --<span class="keyword">global</span> user.email <span class="string">&quot;你的github邮箱地址&quot;</span></span><br></pre></td></tr></table></figure>

<p>ps: 为什么配置好了提交代码到远程分之还是要输入密码? clone的时候选择http</p>
<hr>
<h2 id="clone-pull-push"><a href="#clone-pull-push" class="headerlink" title="clone, pull, push"></a>clone, pull, push</h2><ul>
<li><p>clone: 克隆远程分支到本地</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git clone -b my_branch &lt;远程仓库地址&gt;</span><br></pre></td></tr></table></figure>
</li>
<li><p>pull: 将远程代码pull[拉取]到本地 </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git pull origin branch_name</span><br></pre></td></tr></table></figure>
</li>
<li><p>push: 将本地代码push[推送]到远程</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git add yourfilename</span><br><span class="line">git ci -m <span class="string">&quot;说明修改内容, 常见格式: fix xx bug/add xx function/remove xx file&quot;</span></span><br><span class="line">git push origin branch_name</span><br></pre></td></tr></table></figure>

</li>
</ul>
<hr>
<h2 id="merge-v-s-rebase"><a href="#merge-v-s-rebase" class="headerlink" title="merge v.s. rebase"></a>merge v.s. rebase</h2><ul>
<li>将分支my_branch合并到master分支<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git checkout master</span><br><span class="line">git merge my_branch</span><br><span class="line">git push origin master</span><br></pre></td></tr></table></figure>

</li>
</ul>
<hr>
<h2 id="远程仓库被重命名"><a href="#远程仓库被重命名" class="headerlink" title="远程仓库被重命名"></a>远程仓库被重命名</h2><ul>
<li>远程仓库被重命名</li>
</ul>
<p>Terminal</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ git push origin master</span><br></pre></td></tr></table></figure>
<p>显示</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Counting objects: 3, done.</span><br><span class="line">Delta compression using up to 4 threads.</span><br><span class="line">Compressing objects: 100% (3&#x2F;3), done.</span><br><span class="line">Writing objects: 100% (3&#x2F;3), 294 bytes | 294.00 KiB&#x2F;s, done.</span><br><span class="line">Total 3 (delta 2), reused 0 (delta 0)</span><br><span class="line">remote: Resolving deltas: 100% (2&#x2F;2), completed with 2 local objects.</span><br><span class="line">remote: This repository moved. Please use the new location:</span><br><span class="line">remote:   https:&#x2F;&#x2F;github.com&#x2F;tetsu-upstr&#x2F;JSblog.git</span><br><span class="line">To https:&#x2F;&#x2F;github.com&#x2F;tetsu-upstr&#x2F;blog.git</span><br><span class="line">   7468063..962d5cd  master -&gt; master</span><br></pre></td></tr></table></figure>

<p>输入</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ git remote -v</span><br></pre></td></tr></table></figure>

<p>显示</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">origin  https:&#x2F;&#x2F;github.com&#x2F;tetsu-upstr&#x2F;blog.git (fetch)</span><br><span class="line">origin  https:&#x2F;&#x2F;github.com&#x2F;tetsu-upstr&#x2F;blog.git (push)</span><br></pre></td></tr></table></figure>

<p>Terminal set-url</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ git remote set-url origin https:&#x2F;&#x2F;github.com&#x2F;tetsu-upstr&#x2F;JSblog.git</span><br></pre></td></tr></table></figure>

<p>检查更改</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ git remote -v</span><br></pre></td></tr></table></figure>
<p>显示</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">origin  https:&#x2F;&#x2F;github.com&#x2F;tetsu-upstr&#x2F;JSblog.git (fetch)</span><br><span class="line">origin  https:&#x2F;&#x2F;github.com&#x2F;tetsu-upstr&#x2F;JSblog.git (push)</span><br></pre></td></tr></table></figure>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2020/04/05/Git%20Tutorial/" data-id="ckjuw1zdl000dnbdlejuvc067" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-Faiss" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/04/04/Faiss/" class="article-date">
  <time datetime="2020-04-04T12:11:00.000Z" itemprop="datePublished">2020-04-04</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/RecSys-Machine-Learning/">RecSys & Machine Learning</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/04/04/Faiss/">Faiss</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
      	<!-- Table of Contents -->
		
        <hr>
<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><ul>
<li>A library for efficient similarity search and clustering of dense vectors.Faiss：高效稠密向量相似Top检索库;</li>
<li>Faiss contains several methods for similarity search. It assumes that the instances are represented as vectors and are identified by an integer, and that the vectors can be compared with L2 (Euclidean) distances or dot products. Vectors that are similar to a query vector are those that have the lowest L2 distance or the highest dot product with the query vector. It also supports cosine similarity, since this is a dot product on normalized vectors. Faiss支持多种相似度检索度量：L2距离，点积和余弦相似度。</li>
</ul>
<h2 id="Installation"><a href="#Installation" class="headerlink" title="Installation"></a>Installation</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 更新conda</span></span><br><span class="line">conda update conda</span><br><span class="line"><span class="meta">#</span><span class="bash"> 先安装mkl</span></span><br><span class="line">conda install mkl</span><br><span class="line"><span class="meta">#</span><span class="bash"> gpu版本 -- 记得根据自己安装的cuda版本安装对应的faiss版本，不然会出异常</span></span><br><span class="line">conda install faiss-gpu cudatoolkit=10.0 -c pytorch # For CUDA10</span><br></pre></td></tr></table></figure>

<h2 id="Demo"><a href="#Demo" class="headerlink" title="Demo"></a>Demo</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> faiss</span><br><span class="line">d = <span class="number">64</span>                           <span class="comment"># dimension</span></span><br><span class="line">nb = <span class="number">100000</span>                      <span class="comment"># database size</span></span><br><span class="line">nq = <span class="number">10000</span>                       <span class="comment"># nb of queries</span></span><br><span class="line">np.random.seed(<span class="number">1234</span>)             <span class="comment"># make reproducible</span></span><br><span class="line">xb = np.random.random((nb, d)).astype(<span class="string">&#x27;float32&#x27;</span>)</span><br><span class="line">xq = np.random.random((nq, d)).astype(<span class="string">&#x27;float32&#x27;</span>)</span><br><span class="line">xb[:, <span class="number">0</span>] += np.arange(nb) / <span class="number">1000.</span></span><br><span class="line">xq[:, <span class="number">0</span>] += np.arange(nq) / <span class="number">1000.</span></span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">Faiss is built around the Index object.</span></span><br><span class="line"><span class="string">It encapsulates the set of database vectors, and optionally preprocesses them to make searching efficient.</span></span><br><span class="line"><span class="string">There are many types of indexes,</span></span><br><span class="line"><span class="string">we are going to use the simplest version that just performs brute-force L2 distance search on them: IndexFlatL2.</span></span><br><span class="line"><span class="string">All indexes need to know when they are built which is the dimensionality of the vectors they operate on, d in our case.</span></span><br><span class="line"><span class="string">Then, most of the indexes also require a training phase, to analyze the distribution of the vectors. For IndexFlatL2, we can skip this operation.</span></span><br><span class="line"><span class="string">When the index is built and trained, two operations can be performed on the index: add and search.</span></span><br><span class="line"><span class="string">To add elements to the index, we call add on xb.</span></span><br><span class="line"><span class="string">We can also display the two state variables of the index: is_trained, a boolean that indicates whether training is required and ntotal, the number of indexed vectors.</span></span><br><span class="line"><span class="string">Some indexes can also store integer IDs corresponding to each of the vectors (but not IndexFlatL2).</span></span><br><span class="line"><span class="string">If no IDs are provided, add just uses the vector ordinal as the id, ie. the first vector gets 0, the second 1, etc.</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">index = faiss.IndexFlatL2(d)     <span class="comment"># build the index</span></span><br><span class="line">print(index.is_trained)          <span class="comment"># log: True</span></span><br><span class="line">index.add(xb)                    <span class="comment"># add vectors to the index</span></span><br><span class="line">print(index.ntotal)              <span class="comment"># log: 100000</span></span><br><span class="line">​</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">The basic search operation that can be performed on an index is the k-nearest-neighbor search,</span></span><br><span class="line"><span class="string">ie. for each query vector, find its k nearest neighbors in the database.</span></span><br><span class="line"><span class="string">The result of this operation can be conveniently stored in an integer matrix of size nq-by-k,</span></span><br><span class="line"><span class="string">where row i contains the IDs of the neighbors of query vector i, sorted by increasing distance.</span></span><br><span class="line"><span class="string">In addition to this matrix, the search operation returns a nq-by-k floating-point matrix with the corresponding squared distances.</span></span><br><span class="line"><span class="string">As a sanity check, we can first search a few database vectors, to make sure the nearest neighbor is indeed the vector itself.</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">k = <span class="number">4</span>                          <span class="comment"># we want to see 4 nearest neighbors</span></span><br><span class="line">D, I = index.search(xb[:<span class="number">5</span>], k) <span class="comment"># sanity check</span></span><br><span class="line">print(I)</span><br><span class="line">print(D)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">[[  0 393 363  78]</span></span><br><span class="line"><span class="string"> [  1 555 277 364]</span></span><br><span class="line"><span class="string"> [  2 304 101  13]</span></span><br><span class="line"><span class="string"> [  3 173  18 182]</span></span><br><span class="line"><span class="string"> [  4 288 370 531]]</span></span><br><span class="line"><span class="string">[[0.        7.1751738 7.20763   7.2511625]</span></span><br><span class="line"><span class="string"> [0.        6.3235645 6.684581  6.799946 ]</span></span><br><span class="line"><span class="string"> [0.        5.7964087 6.391736  7.2815123]</span></span><br><span class="line"><span class="string"> [0.        7.2779055 7.527987  7.6628466]</span></span><br><span class="line"><span class="string"> [0.        6.7638035 7.2951202 7.3688145]]</span></span><br><span class="line"><span class="string">the nearest neighbor of each query is indeed the index of the vector,</span></span><br><span class="line"><span class="string">and the corresponding distance is 0. And within a row, distances are increasing.</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">D, I = index.search(xq, k)     <span class="comment"># actual search</span></span><br><span class="line">print(I[:<span class="number">5</span>])                   <span class="comment"># neighbors of the 5 first queries</span></span><br><span class="line">print(I[<span class="number">-5</span>:])                  <span class="comment"># neighbors of the 5 last queries</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">[[ 381  207  210  477]</span></span><br><span class="line"><span class="string"> [ 526  911  142   72]</span></span><br><span class="line"><span class="string"> [ 838  527 1290  425]</span></span><br><span class="line"><span class="string"> [ 196  184  164  359]</span></span><br><span class="line"><span class="string"> [ 526  377  120  425]]</span></span><br><span class="line"><span class="string">[[ 9900 10500  9309  9831]</span></span><br><span class="line"><span class="string"> [11055 10895 10812 11321]</span></span><br><span class="line"><span class="string"> [11353 11103 10164  9787]</span></span><br><span class="line"><span class="string"> [10571 10664 10632  9638]</span></span><br><span class="line"><span class="string"> [ 9628  9554 10036  9582]]</span></span><br><span class="line"><span class="string">Because of the value added to the first component of the vectors,</span></span><br><span class="line"><span class="string">the dataset is smeared along the first axis in d-dim space. </span></span><br><span class="line"><span class="string">So the neighbors of the first few vectors are around the beginning of the dataset,</span></span><br><span class="line"><span class="string">and the ones of the vectors around ~10000 are also around index 10000 in the dataset.</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">To speed up the search, it is possible to segment the dataset into pieces.</span></span><br><span class="line"><span class="string">We define Voronoi cells in the d-dimensional space, and each database vector falls in one of the cells.</span></span><br><span class="line"><span class="string">At search time, only the database vectors y contained in the cell the query x falls in and a few neighboring ones are compared against the query vector.</span></span><br><span class="line"><span class="string">This is done via the IndexIVFFlat index.</span></span><br><span class="line"><span class="string">This type of index requires a training stage, that can be performed on any collection of vectors that has the same distribution as the database vectors.</span></span><br><span class="line"><span class="string">In this case we just use the database vectors themselves.</span></span><br><span class="line"><span class="string">The IndexIVFFlat also requires another index, the quantizer, that assigns vectors to Voronoi cells.</span></span><br><span class="line"><span class="string">Each cell is defined by a centroid, and finding the Voronoi cell a vector falls in consists in finding the nearest neighbor of the vector in the set of centroids.</span></span><br><span class="line"><span class="string">This is the task of the other index, which is typically an IndexFlatL2.</span></span><br><span class="line"><span class="string">There are two parameters to the search method: nlist, the number of cells, and nprobe, the number of cells (out of nlist) that are visited to perform a search.</span></span><br><span class="line"><span class="string">The search time roughly increases linearly with the number of probes plus some constant due to the quantization.</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">nlist = <span class="number">100</span>                       <span class="comment"># 聚类中心个数</span></span><br><span class="line">k = <span class="number">4</span></span><br><span class="line">quantizer = faiss.IndexFlatL2(d)  <span class="comment"># the other index</span></span><br><span class="line">index = faiss.IndexIVFFlat(quantizer, d, nlist)</span><br><span class="line"><span class="keyword">assert</span> <span class="keyword">not</span> index.is_trained</span><br><span class="line">index.train(xb)</span><br><span class="line"><span class="keyword">assert</span> index.is_trained</span><br><span class="line"></span><br><span class="line">index.add(xb)                  <span class="comment"># add may be a bit slower as well</span></span><br><span class="line">D, I = index.search(xq, k)     <span class="comment"># actual search</span></span><br><span class="line">print(I[<span class="number">-5</span>:])                  <span class="comment"># neighbors of the 5 last queries</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">[[ 9900  9309  9810 10048]</span></span><br><span class="line"><span class="string"> [11055 10895 10812 11321]</span></span><br><span class="line"><span class="string"> [11353 10164  9787 10719]</span></span><br><span class="line"><span class="string"> [10571 10664 10632 10203]</span></span><br><span class="line"><span class="string"> [ 9628  9554  9582 10304]]</span></span><br><span class="line"><span class="string">The values are similar, but not exactly the same as for the brute-force search (see above).</span></span><br><span class="line"><span class="string">This is because some of the results were not in the exact same Voronoi cell.</span></span><br><span class="line"><span class="string">Therefore, visiting a few more cells may prove useful. &#x27;</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">index.nprobe = <span class="number">10</span>              <span class="comment"># default nprobe is 1, try a few more 默认聚类中心个数1, 尝试调大中心数10</span></span><br><span class="line">D, I = index.search(xq, k)</span><br><span class="line">print(I[<span class="number">-5</span>:])                  <span class="comment"># neighbors of the 5 last queries</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">[[ 9900 10500  9309  9831]</span></span><br><span class="line"><span class="string"> [11055 10895 10812 11321]</span></span><br><span class="line"><span class="string"> [11353 11103 10164  9787]</span></span><br><span class="line"><span class="string"> [10571 10664 10632  9638]</span></span><br><span class="line"><span class="string"> [ 9628  9554 10036  9582]]</span></span><br><span class="line"><span class="string">which is the correct result.</span></span><br><span class="line"><span class="string">Note that getting a perfect result in this case is merely an artifact of the data distribution,</span></span><br><span class="line"><span class="string">as it is has a strong component on the x-axis which makes it easier to handle.</span></span><br><span class="line"><span class="string">The nprobe parameter is always a way of adjusting the tradeoff between speed and accuracy of the result.</span></span><br><span class="line"><span class="string">Setting nprobe = nlist gives the same result as the brute-force search (but slower).</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">ngpus = faiss.get_num_gpus()</span><br><span class="line">print(<span class="string">&#x27;number of GPUS:&#x27;</span>, ngpus)</span><br><span class="line">res = faiss.StandardGpuResources()</span><br><span class="line"><span class="comment"># build a flat (CPU) index</span></span><br><span class="line">index_flat = faiss.IndexFlatL2(d)</span><br><span class="line"><span class="comment"># make it into a gpu index</span></span><br><span class="line">gpu_index_flat = faiss.index_cpu_to_gpu(res, <span class="number">0</span>, index_flat)</span><br><span class="line">gpu_index_flat.add(xb)</span><br><span class="line">print(gpu_index_flat.ntotal)</span><br><span class="line">D, I = gpu_index_flat.search(xq, k)     <span class="comment"># actual search</span></span><br><span class="line">print(I[:<span class="number">5</span>])                            <span class="comment"># neighbors of the 5 first queries</span></span><br><span class="line">print(I[<span class="number">-5</span>:])                           <span class="comment"># neighbors of the 5 last queries</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># add self defined index</span></span><br><span class="line">index = faiss.IndexFlatL2(xb.shape[<span class="number">1</span>])</span><br><span class="line">ids = np.arange(xb.shape[<span class="number">0</span>]) + <span class="number">231</span></span><br><span class="line">index2 = faiss.IndexIDMap(index)</span><br><span class="line">index2.add_with_ids(xb, ids)</span><br><span class="line">k = <span class="number">4</span>                                   <span class="comment"># we want to see 4 nearest neighbors</span></span><br><span class="line">D, I = index2.search(xq, k)             <span class="comment"># actual search</span></span><br><span class="line">print(I[:<span class="number">5</span>])                            <span class="comment"># neighbors of the 5 first queries</span></span><br><span class="line">print(I[<span class="number">-5</span>:])                           <span class="comment"># neighbors of the 5 last queries</span></span><br></pre></td></tr></table></figure>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2020/04/04/Faiss/" data-id="ckjuw1zdk000cnbdldtqjhd2o" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-The Economics of Money, Banking, and Financial Markets" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/04/04/The%20Economics%20of%20Money,%20Banking,%20and%20Financial%20Markets/" class="article-date">
  <time datetime="2020-04-04T12:11:00.000Z" itemprop="datePublished">2020-04-04</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Reading/">Reading</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/04/04/The%20Economics%20of%20Money,%20Banking,%20and%20Financial%20Markets/">The Economics of Money, Banking, and Financial Markets</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
      	<!-- Table of Contents -->
		
        <hr>
<h2 id="理解利率"><a href="#理解利率" class="headerlink" title="理解利率"></a>理解利率</h2>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2020/04/04/The%20Economics%20of%20Money,%20Banking,%20and%20Financial%20Markets/" data-id="ckjuw1zdx0011nbdl3nlsf1t6" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-狼人杀如何致胜" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/03/22/%E7%8B%BC%E4%BA%BA%E6%9D%80%E5%A6%82%E4%BD%95%E8%87%B4%E8%83%9C/" class="article-date">
  <time datetime="2020-03-21T18:12:57.000Z" itemprop="datePublished">2020-03-22</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Always-Review/">Always Review</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/03/22/%E7%8B%BC%E4%BA%BA%E6%9D%80%E5%A6%82%E4%BD%95%E8%87%B4%E8%83%9C/">狼人杀如何致胜</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
      	<!-- Table of Contents -->
		
        <hr>
<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><ul>
<li>到底是一个重点是靠盘逻辑的游戏？还是一个缺少逻辑、更多的是表演/发言/说谎的游戏？逻辑在获胜上占到多少比重？</li>
<li>表演是这个游戏里面重要的部分。如何正确的从自己的角色表演，达到获胜的目的。</li>
<li>作为游戏，均存在玩物丧志属性，总结游戏玩法也是符合让这个游戏对于我的边际效益最小化的目的，鼓励投入到新领域中去。</li>
<li>本文重点是9人国标局。3民3狼1预1巫1猎。12人局存在玩家质量参差不齐的局面。</li>
</ul>
<h2 id="获胜之道"><a href="#获胜之道" class="headerlink" title="获胜之道"></a>获胜之道</h2><ul>
<li>总结一下玩到现在如何获得胜利的方法，理论不一定严谨，整体目的是避免一些错误的发言和节奏，梳理一些关键性的要点，在整体上最大化胜率。重点解析预言家和狼人这两个角色。</li>
</ul>
<h5 id="预言家"><a href="#预言家" class="headerlink" title="预言家"></a>预言家</h5><ul>
<li>预言家是9人局胜率最低的角色，这是由于规则决定的（大概率双神起跳）。</li>
<li>作为预言家必须非常坦然接受你死的很快或者你死的很冤的事实。</li>
<li>发言的时候必须快速清晰的报出来查验，以免还没有说出来任何查验只透露自己身份然后被狼人自爆。预言家在遗言的时候。一定要多说。即使是非常冤死。但是真预言家的求生欲一定不能过低。</li>
</ul>
<h5 id="狼人"><a href="#狼人" class="headerlink" title="狼人"></a>狼人</h5><ul>
<li>狼人的胜利关键在于“顺势而为”，三只狼人需要各自独立地根据场上的形势因时制宜的选择悍跳/划水/引导/站边/跟票/冲票。</li>
<li>同时三狼要有一定程度的分工，整体态势太趋同（都怂或者都悍跳）风险的。</li>
</ul>
<h2 id="案例复盘"><a href="#案例复盘" class="headerlink" title="案例复盘"></a>案例复盘</h2><h4 id="失败的一局复盘"><a href="#失败的一局复盘" class="headerlink" title="失败的一局复盘"></a>失败的一局复盘</h4><div style="text-align: center;">
<img alt="" src="https://i.loli.net/2020/09/14/QYTr83RcIsd4qWh.jpg" style="display: inline-block;" width="200"/>
</div>


<ul>
<li>图上这局是我玩的比较失败的一局。结果：作为好人阵营（猎人）我们输的非常彻底，被一只悍跳狼完全带了节奏，狼人预言家身份坐实，民整体没有视角做得出的选择也都是错误的，神职女巫和猎人完全齐齐的走向了错误的做法。</li>
</ul>
<p>这局的特殊在于 </p>
<ol>
<li>一局下来好人之间几乎没有形成提供有效的通讯（统计来看9人国标局好人输概率大于50%，但是好人们几乎完全没有相互之间的信息认可，这种是绝对不算多的案例）。</li>
<li>悍跳狼第一天就被投死，其余怂狼从头到尾也没有也没有太多行动。但是好人掉进圈套里完全出不来，后续决策是一连串错误，而且是走向那种温水煮青蛙的错误节奏。</li>
<li>整局游戏来看，好人绝对不是一定输，是肯定机会逆转的，但是整体上我认为好人如果想赢非常艰难，故做一下复盘。</li>
</ol>
<h4 id="重点历程"><a href="#重点历程" class="headerlink" title="重点历程"></a>重点历程</h4><ol start="0">
<li><p>狼人刀3号女巫，3女巫自救。9预言家8金水。</p>
</li>
<li><p>第一天9号第一个发言，说自己预言家给8号的民发了金水，发言过程中没有明显语气或者逻辑上的问题。然后说由于7、8、9位置学，轻踩一下7号。接着顺次12345发言均没有有效信息，其中女巫跳出来身份说明是自救的。<br>8号是归票位，给8发出去金水，然后8又没有身份，我当时认为信服力不一定。<br>但是8不是神职，如果9是狼人发到8民身上，可能性也是存在的，发言上没有明显问题，当时我没有完全不信或者不信。</p>
</li>
<li><p>然后6号发言，给7号发了查杀。<br>从位置上来看，9预言家8号金水则7号位置有些尴尬。<br>6给7查杀，当时我是不太信的，然后7号是民，但7的角度而言，6和9对7都有一定攻击性。但6是查杀，他从自身身份出发只能从发言打死6。</p>
</li>
<li><p>第一天投票：我上票给了7号，6整体发言语气和逻辑都还好（6查验的是后位置的7有合理性，感觉9的力度不太好说，其实我这里操作有一定的赌博性，我是猎人从容错的角度出发可以这么投）。但是结果4，7，8，9投6，结果6出局。<br>这里狼人有个破绽，2和5选择了弃票。但当时在69发言都没有明显破绽的情况下，我对这个弃票没有太怀疑，思考的重点还是6/9谁是真预言家上。</p>
</li>
<li><p>6号发表遗言：<br>6发言整体比较激动，语气没问题像真预言家，用了4张加时卡，逻辑上看整体发言就表达一个他的逻辑：9预8金，则7是位置及其尴尬的一张牌。如果6是一只狼人，为什么不隐藏自己的身份，大概率把7打出去呢。为什么一定要站出来把7打死，铁铁的要打死这张7呢。<br>这里无非两种情况（当时我没有把这两种情况盘的非常清楚）：</p>
<ol>
<li>6是真预言家，验出来7是狼人，然后从到尾踩死这个7。 </li>
<li>6是狼人，这个狼人选择很冒险却收益很小的一步，冒着自己被投出去的风险杀死7这个民。他的风险在于大家可能不信他是真预言家（事实上第一轮投票大家真没相信）。因为9首位发言给归票位金水预言家面还是有一些的。<br>然后这里1我、3巫、还有4民这三个人无一例外心路历程都是上述第1种，相信了6是真预言家。当时怎么看觉得呢这个6非要踩死这个7，从他的狼人视角来看真的收益好小。</li>
</ol>
</li>
<li><p>第二天晚上9真预查验的是1猎（就是我）是好人，女巫因为是认定6真预言家，所以必然是要开毒，选择毒7。狼人杀了3女巫。<br>然后第二天我是最后发言的归票位。然后第二天白天发言2号没什么信息，3女巫被杀，4民5狼发言如下：<br>4民说了自己觉得信了6真预言家，理由就是感觉上一局6狼的话收益太小。且现在9还活着。表示想上票给9。<br>5狼发言表示和4的逻辑一样，同理觉得6狼的话收益太小。同想上票9。这时候我的心路历程和他俩一样一样的。<br>9真预言家发言，说查验了我是好人。但是9没有怎么盘6的问题。我没有信他的金水。 我觉得9的验人这个力度从9是好人说没问题，因为上一局我给他上了一票，是正确的验人选择。但是反过来从9狼人说也是存在可能性的，拉拢一个好人进来。另外我觉得2如果是真预言家在2天没死的情况下又2天验出来都是好人，内心当时确实存疑。其实从复盘看，他的验人选择真的就是单纯的真预言家好人的视角的做法没什么多想的，但是当时我和其他好人4、8真的没有认下来他的真预言家身份。<br>8民对于9第一天给他的金水不敢接。且他认为狼人第二天没杀9他心存疑惑。8表示要投票给9。<br>1猎人我，我逻辑和4和5一样也走在相信6的道路上。一方面是信了6，另一方面9的发言似乎没怎么针对过6号。这个我心存疑惑。然后我就balabala一直分析6如果是狼人第一天收益太小的事实，希望大家上票给9。</p>
</li>
<li><p>结果：大家上票给9。9出局，9没有太深入的盘逻辑。</p>
</li>
<li><p>第三天夜晚，狼人选择了杀8号。场上剩下四个人：1猎2狼4民5狼。双狼控场游戏结束。</p>
</li>
</ol>
<h4 id="要点总结"><a href="#要点总结" class="headerlink" title="要点总结"></a>要点总结</h4><ol>
<li><p>狼怎么玩的：<br>6狼（胜利方mvp）给7踩死的查杀。这种其实是根据位置学的反逻辑。用冒着自己的危险踩死7的视角，尝试自己的死换来的是强有力的预言家，表面看坐实的程度不低。<br>2号怂狼没有透出任何信息。<br>5狼略微引导了一下6是预言家的逻辑，但是1猎3巫4民确实是想到一块了（我当时确实从6悍跳预言家收益晓得角度认了6预言家，且在我之前发言的4民也是想到了且发言的），并不是因为跟了5的逻辑。</p>
</li>
<li><p>好人怎么玩的：<br>1猎，3巫，4民：其中这三个都是认为6作为狼人可能的收益很小的角度上，认定6可能是真预言家。后面女巫顺势开毒。其他均给9上票。<br>8民，第一天金水没有接也合理。因为6狼发言没有太大问题，9预言家的金水给8也不一定能坐实9。</p>
</li>
<li><p>这一局的独特性，为什么我总觉得这局好人难赢，为什么说这一局不容易太逆转。</p>
<ol>
<li>首先女巫自救没有银水。少验一个人。</li>
<li>预言家是首置位发言，给8民一个金水。8民是金水正好也是归票位的金水。在8是民的情况下。金水可接可不接。预言家可认可不认。（我觉得这里是在赌概率）。且第二天白天预言家这个发言我觉得有不足。</li>
<li>7号民牌，开不了视角。只能反打6，9号一开始根据位置学轻踩7，能说的大致就那么多。</li>
<li>2和5第一天的弃票是狼人一个重要的破绽，回过头来想想第一天好人正常逻辑大概率是不会弃票，肯定是6和7的局。弃票则说明真的狼面很大。但是为什么这个看起来暴露的弃票行为没有获得理论上足够的重视呢？我理解因为6最后遗言这一手。基本上把所有的思路都引入在真预言家身上=&gt;所有好人的当务之急，或者急需抿身份的思路都是【谁是真预言家】这个问题。如果真是6预9狼。9是要马上要投出去的牌。或者要干掉这个被6验出来的7号或者从位置学上被尴尬的7号。总之好人视角来看，7/9两张牌都有争议。无论是7/9出1狼或者7和9狼踩狼，【排7/9的身份或者狼坑】整体执行优先级都高于对于【好人对弃票的反馈】。</li>
</ol>
</li>
</ol>
<h4 id="为什么这局难以逆转"><a href="#为什么这局难以逆转" class="headerlink" title="为什么这局难以逆转"></a>为什么这局难以逆转</h4><p>如果发生以下条件，那么6号预言家难坐实，局势也不会这么发展。</p>
<ol>
<li>第一天狼人没有刀女巫。换来一个银水。</li>
<li>7号8号两个里面存在一个神。真实情况是7、8两位置连民，都整体缺少视角，7被毒冤死，另8缺少足够信息。</li>
<li>第一天9号真预言家不是第一个发言。且给的不是归票位验人。</li>
<li>真预言家在2天内至少验出来一匹狼。且最好第二天验出来狼。1/2/4/5的身份从头到尾巴除了2/5第一天弃票这个信息。基本上发言没有透露太多信息或者破绽。好人从头到位都有点缺乏信息。</li>
</ol>
<h4 id="这局如果好人想赢，怎么赢："><a href="#这局如果好人想赢，怎么赢：" class="headerlink" title="这局如果好人想赢，怎么赢："></a>这局如果好人想赢，怎么赢：</h4><ol>
<li><p>真预言家9，作为场上唯一有视野的人：</p>
<ol>
<li>努力去向全场好人去仔仔细细盘6号这匹狼的狼人意图。语态上始终坚持狠狠的打死6这只狼不动摇。（我认为这个不太容易让好人相信，但是是必要要尝试去做的不能不这么做。）</li>
<li>努力推进打平衡局的玩法。暂时保住7号。表示自己可以扛出，将7当做反向金水。一定建议让女巫不要毒7，哪怕毒自己，打一个平衡局，自己扛出。走1预1狼平衡局，真预言家出局后续走向纯盘逻辑的局。</li>
</ol>
</li>
<li><p>第二天的金水我接住。认同9号的验人逻辑。就是因为我第一天给他上票他验了我。结果是金水。就是这么回事没什么好说的。然后我转过来思维从剩余的人里面出。</p>
</li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2020/03/22/%E7%8B%BC%E4%BA%BA%E6%9D%80%E5%A6%82%E4%BD%95%E8%87%B4%E8%83%9C/" data-id="ckjuw1ze5001mnbdl82la9w65" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-David Stern, who turned NBA into powerhouse" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/02/18/David%20Stern,%20who%20turned%20NBA%20into%20powerhouse/" class="article-date">
  <time datetime="2020-02-18T14:56:00.000Z" itemprop="datePublished">2020-02-18</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Reading/">Reading</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/02/18/David%20Stern,%20who%20turned%20NBA%20into%20powerhouse/">David Stern, who turned NBA into powerhouse</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
      	<!-- Table of Contents -->
		
        <hr>
<h2 id="NBA，一个世界联盟"><a href="#NBA，一个世界联盟" class="headerlink" title="NBA，一个世界联盟"></a>NBA，一个世界联盟</h2><ul>
<li>从小学时期到现在（2020），NBA贯穿了我的整个成长过程。今天，NBA是一个强大的商业联盟，是一种文化现象，但在早期是一个美国非常边缘的联赛。</li>
<li>大卫斯特恩，已故NBA总裁在30年间做对了几个关键决策。本文思考NBA如何从一个美国边缘联赛，成为一种席卷全球的文化现象。</li>
</ul>
<hr>
<h2 id="大卫·斯特恩留给NBA的遗产"><a href="#大卫·斯特恩留给NBA的遗产" class="headerlink" title="大卫·斯特恩留给NBA的遗产"></a>大卫·斯特恩留给NBA的遗产</h2><ul>
<li>一句话总结：斯特恩把NBA从”职业篮球比赛”变成了”现代体育秀”。NBA不是单纯的一种体育竞技，而是成了一种强大制星能力、强娱乐性的大众文化。有明星、有恩怨、有表演。</li>
<li>改变NBA的规则，让观众觉得不虚此行、看的过瘾。</li>
</ul>
<hr>
<h5 id="竞技平衡性的政策"><a href="#竞技平衡性的政策" class="headerlink" title="竞技平衡性的政策"></a>竞技平衡性的政策</h5><p>Why平衡性?</p>
<ul>
<li>NBA每支球队处于美国不同的城市，经济水平方差很大。大城市薪水高，小城市开不出薪水。实力越强的球员大概率就去大城市。所以强队越强，弱队越弱。是一种不够健康的发展态势。</li>
<li>从观众的角度来看，强队虐弱队，缺乏看点。水平旗鼓相当的对抗，最吸引人。因此问题转化为，如何让整体联盟每只球队实力差距不要太大。</li>
</ul>
<h5 id="出台”工资帽”制度。"><a href="#出台”工资帽”制度。" class="headerlink" title="出台”工资帽”制度。"></a>出台”工资帽”制度。</h5><ul>
<li>每个球队工资总和有个硬性上限，大幅度在整体上实力差距很小。（不是没有差距，是让这种差距在一种可以良性发展的范围内，可以接受的范围内）</li>
</ul>
<h5 id="调整选秀政策"><a href="#调整选秀政策" class="headerlink" title="调整选秀政策"></a>调整选秀政策</h5><ul>
<li>改变早期选秀制度的弊端。成绩越差的球队，下一年会有更好的顺位。因此有的球队在第一年肉眼可见拿不到好成绩的时候，就会选择”来年再战，破罐子破摔”这种策略。因此战绩惨不忍睹，观赏性下降。</li>
<li>排名垫底的若干只球队，都有概率获得状元签，而不是最差的那一只球队。个人感觉就是引入了一些噪声，使得最垫底的球队，自己的想法实现起来有巨大困难，迫使整体而言还是需要把名次向上提升。</li>
</ul>
<h5 id="政策鼓励球员得分"><a href="#政策鼓励球员得分" class="headerlink" title="政策鼓励球员得分"></a>政策鼓励球员得分</h5><ul>
<li>2004引入No Handcheck政策，防守者对于进攻者的身体接触，不能太大。说白了就是让球员的阻碍作用不能太狠，大大增加了更多上篮得分机会。典型的例子就是哈登这种，对于类似的规则相当收益。大大提升了外线球员爆炸性得分的可能性。</li>
<li>这种政策的效果就是对于造星的效果提升十分明显。有更多的球员有个人突出的表现。明星效应来的比之前强很多。</li>
</ul>
<h5 id="改变NBA的产品形式：从”比赛”到”球星”"><a href="#改变NBA的产品形式：从”比赛”到”球星”" class="headerlink" title="改变NBA的产品形式：从”比赛”到”球星”"></a>改变NBA的产品形式：从”比赛”到”球星”</h5><ul>
<li><p>相比于打造比赛，斯特恩更专注与把一个个球员打造成有故事的产品。你想起来一些球员，可能不是他的名字，而是外号。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">约翰逊、拉里伯德、乔丹、詹姆斯、杜兰特、贾巴尔、加内特、邓肯、罗斯、霍华德</span><br></pre></td></tr></table></figure>
<p>对比</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&quot;魔术师&quot;、&quot;大鸟&quot;、&quot;飞人&quot;、&quot;小皇帝&quot;、&quot;死神&quot;、&quot;天沟&quot;、&quot;狼王&quot;、&quot;石佛&quot;、&quot;风城玫瑰&quot;、&quot;魔兽&quot;</span><br></pre></td></tr></table></figure>
<p>下面一行称号显然比上面那行更有吸引力、有故事感。</p>
</li>
<li><p>塑造豪门对决和恩怨情仇。例如，拉里伯德 v.s. 魔术师这两个时代巨星。凯尔特人 v.s. 湖人两支历史豪门对决</p>
</li>
<li><p>热火三巨头：巅峰老詹、巅峰韦德、龙王波什。三个当之无愧的球队老大放在一支球队，能否无敌？</p>
</li>
<li><p>各种”反叛”、”背叛”的文化。每段时间都会塑造一些争议人物。杜兰特投敌是对是错？给我的角度我认为追求总冠军是是没错的，同时对于俄克拉荷马也不欠什么，但是大多数球迷可能认为杜兰特背叛了俄克拉荷马。</p>
</li>
<li><p>造星推进手段1：全明星赛。NBA全明星赛是造星思想的最好体现。开场前的主持人依次介绍每个球员。还会请明星来演唱。绝对不仅仅是一场单纯的经济体育。在全明星赛上面基本上球员不怎么加强防守（多数只有比赛最后一节才认真），以各种夸张的扣篮、空接为主，即使是不爱看篮球的，看完都会很过瘾。</p>
</li>
</ul>
<p>拉文罚球线扣篮</p>
<ul>
<li>造星推进手段2：”圣诞大战” 。安排最强的几支队伍在圣诞节期间强强对话，几乎是额外增加一次重演季后赛决赛或者东西部半决赛的看点。</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2020/02/18/David%20Stern,%20who%20turned%20NBA%20into%20powerhouse/" data-id="ckjuw1zdi0008nbdl050h9rh8" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-Linux Commands" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/02/18/Linux%20Commands/" class="article-date">
  <time datetime="2020-02-18T14:56:00.000Z" itemprop="datePublished">2020-02-18</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Programming-Data/">Programming & Data</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/02/18/Linux%20Commands/">Linux Commands</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
      	<!-- Table of Contents -->
		
        <hr>
<h2 id="du"><a href="#du" class="headerlink" title="du"></a>du</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">du (disk usage) : 查看磁盘使用空间；</span><br><span class="line">du -sh filename/dirname</span><br></pre></td></tr></table></figure>

<h2 id="nohup"><a href="#nohup" class="headerlink" title="nohup"></a>nohup</h2><ul>
<li>When you execute a Unix job in the background ( using &amp;, bg command), and logout from the session, your process will get killed. You can avoid this using several methods — executing the job with nohup, or making it as batch job using at, batch or cron command. Nohup stands for no hang up, which can be executed as shown below. nohup syntax:<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nohup command &amp;</span><br></pre></td></tr></table></figure></li>
<li>Nohup is very helpful when you have to execute a shell-script or command that take a long time to finish. In that case, you don’t want to be connected to the shell and waiting for the command to complete. Instead, execute it with nohup, exit the shell and continue with your other work.<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ps -aux | grep charm</span><br></pre></td></tr></table></figure></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2020/02/18/Linux%20Commands/" data-id="ckjuw1zdp000knbdl21sreoe3" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-Recurrent Neural Network" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/02/13/Recurrent%20Neural%20Network/" class="article-date">
  <time datetime="2020-02-13T14:56:00.000Z" itemprop="datePublished">2020-02-13</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/RecSys-Machine-Learning/">RecSys & Machine Learning</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/02/13/Recurrent%20Neural%20Network/">Recurrent Neural Network</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
      	<!-- Table of Contents -->
		
        <hr>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2020/02/13/Recurrent%20Neural%20Network/" data-id="ckjuw1zdt000rnbdlboja5jqy" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-Tensorflow API" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/02/13/Tensorflow%20API/" class="article-date">
  <time datetime="2020-02-13T14:56:00.000Z" itemprop="datePublished">2020-02-13</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Programming-Data/">Programming & Data</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/02/13/Tensorflow%20API/">Tensorflow API</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
      	<!-- Table of Contents -->
		
        <hr>
<h2 id="tf-nn-embedding-lookup"><a href="#tf-nn-embedding-lookup" class="headerlink" title="tf.nn.embedding_lookup()"></a>tf.nn.embedding_lookup()</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">tf.nn.embedding_lookup(</span><br><span class="line">    params,</span><br><span class="line">    ids,</span><br><span class="line">    partition_strategy=<span class="string">&#x27;mod&#x27;</span>,</span><br><span class="line">    name=<span class="literal">None</span>,</span><br><span class="line">    validate_indices=<span class="literal">True</span>,</span><br><span class="line">    max_norm=<span class="literal">None</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>Looks up ids in a list of embedding tensors. This function is used to perform parallel lookups on the list of tensors in params. It is a generalization of tf.gather, where params is interpreted as a partitioning of a large embedding tensor. params may be a PartitionedVariable as returned by using tf.get_variable() with a partitioner. 按照ids顺序返回params中的第ids行。</p>
<ul>
<li>If len(params) &gt; 1, each element id of ids is partitioned between the elements of params according to the partition_strategy. In all strategies, if the id space does not evenly divide the number of partitions, each of the first (max_id + 1) % len(params) partitions will be assigned one more id.</li>
<li>If partition_strategy is “mod”, we assign each id to partition p = id % len(params). For instance, 13 ids are split across 5 partitions as: [[0, 5, 10], [1, 6, 11], [2, 7, 12], [3, 8], [4, 9]]</li>
<li>If partition_strategy is “div”, we assign ids to partitions in a contiguous manner. In this case, 13 ids are split across 5 partitions as: [[0, 1, 2], [3, 4, 5], [6, 7, 8], [9, 10], [11, 12]]</li>
</ul>
<p>The results of the lookup are concatenated into a dense tensor. The returned tensor has shape shape(ids) + shape(params)[1:].</p>
<p>demo</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">a = np.array(</span><br><span class="line">    [[<span class="number">0.1</span>, <span class="number">0.2</span>, <span class="number">0.3</span>],</span><br><span class="line">     [<span class="number">1.1</span>, <span class="number">1.2</span>, <span class="number">1.3</span>],</span><br><span class="line">     [<span class="number">2.1</span>, <span class="number">2.2</span>, <span class="number">2.3</span>],</span><br><span class="line">     [<span class="number">3.1</span>, <span class="number">3.2</span>, <span class="number">3.3</span>],</span><br><span class="line">     [<span class="number">4.1</span>, <span class="number">4.2</span>, <span class="number">4.3</span>]])</span><br><span class="line">idx1 = tf.Variable([<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>], tf.int32)</span><br><span class="line">idx2 = tf.Variable([[<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>], [<span class="number">4</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="number">2</span>]], tf.int32)</span><br><span class="line">out1 = tf.nn.embedding_lookup(a, idx1)</span><br><span class="line">out2 = tf.nn.embedding_lookup(a, idx2)</span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(init)</span><br><span class="line">    print(a)</span><br><span class="line">    print(<span class="string">&#x27;=========&#x27;</span>)</span><br><span class="line">    print(sess.run(out1))</span><br><span class="line">    print(<span class="string">&#x27;=========&#x27;</span>)</span><br><span class="line">    print(sess.run(out2))</span><br></pre></td></tr></table></figure>
<p>result</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">[[<span class="number">0.1</span> <span class="number">0.2</span> <span class="number">0.3</span>]</span><br><span class="line"> [<span class="number">1.1</span> <span class="number">1.2</span> <span class="number">1.3</span>]</span><br><span class="line"> [<span class="number">2.1</span> <span class="number">2.2</span> <span class="number">2.3</span>]</span><br><span class="line"> [<span class="number">3.1</span> <span class="number">3.2</span> <span class="number">3.3</span>]</span><br><span class="line"> [<span class="number">4.1</span> <span class="number">4.2</span> <span class="number">4.3</span>]]</span><br><span class="line">=========</span><br><span class="line">[[<span class="number">0.1</span> <span class="number">0.2</span> <span class="number">0.3</span>]</span><br><span class="line"> [<span class="number">2.1</span> <span class="number">2.2</span> <span class="number">2.3</span>]</span><br><span class="line"> [<span class="number">3.1</span> <span class="number">3.2</span> <span class="number">3.3</span>]</span><br><span class="line"> [<span class="number">1.1</span> <span class="number">1.2</span> <span class="number">1.3</span>]]</span><br><span class="line">=========</span><br><span class="line">[[[<span class="number">0.1</span> <span class="number">0.2</span> <span class="number">0.3</span>]</span><br><span class="line">  [<span class="number">2.1</span> <span class="number">2.2</span> <span class="number">2.3</span>]</span><br><span class="line">  [<span class="number">3.1</span> <span class="number">3.2</span> <span class="number">3.3</span>]</span><br><span class="line">  [<span class="number">1.1</span> <span class="number">1.2</span> <span class="number">1.3</span>]]</span><br><span class="line"> [[<span class="number">4.1</span> <span class="number">4.2</span> <span class="number">4.3</span>]</span><br><span class="line">  [<span class="number">0.1</span> <span class="number">0.2</span> <span class="number">0.3</span>]</span><br><span class="line">  [<span class="number">2.1</span> <span class="number">2.2</span> <span class="number">2.3</span>]</span><br><span class="line">  [<span class="number">2.1</span> <span class="number">2.2</span> <span class="number">2.3</span>]]]</span><br></pre></td></tr></table></figure>


<h2 id="tf-sequence-mask"><a href="#tf-sequence-mask" class="headerlink" title="tf.sequence_mask"></a>tf.sequence_mask</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">tf.sequence_mask(</span><br><span class="line">    lengths,</span><br><span class="line">    maxlen=<span class="literal">None</span>,</span><br><span class="line">    dtype=tf.bool,</span><br><span class="line">    name=<span class="literal">None</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p>Returns a mask tensor representing the first N positions of each cell. If lengths has shape [d_1, d_2, …, d_n] the resulting tensor mask has dtype dtype and shape [d_1, d_2, …, d_n, maxlen], with<br>mask[i_1, i_2, …, i_n, j] = (j &lt; lengths[i_1, i_2, …, i_n])</p>
<p>Examples:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tf.sequence_mask([<span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>], <span class="number">5</span>) </span><br><span class="line"><span class="comment"># [[True, False, False, False, False], </span></span><br><span class="line"><span class="comment"># [True, True, True, False, False], </span></span><br><span class="line"><span class="comment"># [True, True, False, False, False]] </span></span><br></pre></td></tr></table></figure>
<p>另外</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tf.sequence_mask([[<span class="number">1</span>, <span class="number">3</span>],[<span class="number">2</span>,<span class="number">0</span>]]) </span><br><span class="line"><span class="comment"># [[[True, False, False], </span></span><br><span class="line"><span class="comment"># [True, True, True]], </span></span><br><span class="line"><span class="comment"># [[True, True, False], </span></span><br><span class="line"><span class="comment"># [False, False, False]]]</span></span><br></pre></td></tr></table></figure>

<h2 id="tf-expand-dims"><a href="#tf-expand-dims" class="headerlink" title="tf.expand_dims"></a>tf.expand_dims</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">tf.expand_dims( </span><br><span class="line">    input, </span><br><span class="line">    axis=<span class="literal">None</span>, </span><br><span class="line">    name=<span class="literal">None</span>, </span><br><span class="line">    dim=<span class="literal">None</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>See the guide: Tensor Transformations &gt; Shapes and Shaping</p>
<p>Inserts a dimension of 1 into a tensor’s shape.</p>
<p>Given a tensor input, this operation inserts a dimension of 1 at the dimension index axis of input’s shape. The dimension index axis starts at zero; if you specify a negative number for axis it is counted backward from the end.</p>
<p>This operation is useful if you want to add a batch dimension to a single element. For example, if you have a single image of shape [height, width, channels], you can make it a batch of 1 image with expand_dims(image, 0), which will make the shape [1, height, width, channels].</p>
<p>Other examples:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># &#x27;t&#x27; is a tensor of shape [2]</span></span><br><span class="line">tf.shape(tf.expand_dims(t, <span class="number">0</span>))  <span class="comment"># [1, 2]</span></span><br><span class="line">tf.shape(tf.expand_dims(t, <span class="number">1</span>))  <span class="comment"># [2, 1]</span></span><br><span class="line">tf.shape(tf.expand_dims(t, <span class="number">-1</span>))  <span class="comment"># [2, 1]</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># &#x27;t2&#x27; is a tensor of shape [2, 3, 5]</span></span><br><span class="line">tf.shape(tf.expand_dims(t2, <span class="number">0</span>))  <span class="comment"># [1, 2, 3, 5]</span></span><br><span class="line">tf.shape(tf.expand_dims(t2, <span class="number">2</span>))  <span class="comment"># [2, 3, 1, 5]</span></span><br><span class="line">tf.shape(tf.expand_dims(t2, <span class="number">3</span>))  <span class="comment"># [2, 3, 5, 1]</span></span><br></pre></td></tr></table></figure>
<p>This operation requires that:</p>
<p>-1-input.dims() &lt;= dim &lt;= input.dims()</p>
<p>This operation is related to squeeze(), which removes dimensions of size 1.</p>
<h2 id="tf-gather"><a href="#tf-gather" class="headerlink" title="tf.gather()"></a>tf.gather()</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">tf.gather( </span><br><span class="line">    params, </span><br><span class="line">    indices, </span><br><span class="line">    validate_indices=<span class="literal">None</span>,</span><br><span class="line">    name=<span class="literal">None</span>, </span><br><span class="line">    axis=<span class="number">0</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>indices must be an integer tensor of any dimension (usually 0-D or 1-D). Produces an output tensor with shape params.shape[:axis] + indices.shape + params.shape[axis + 1:] where:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">x = tf.range(<span class="number">0</span>, <span class="number">10</span>)*<span class="number">10</span> + tf.constant(<span class="number">1</span>, shape=[<span class="number">10</span>])</span><br><span class="line">y = tf.gather(x, [<span class="number">1</span>, <span class="number">5</span>, <span class="number">9</span>])</span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    print(sess.run(x))</span><br><span class="line">    print(sess.run(y))</span><br></pre></td></tr></table></figure>

<p>result</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[ <span class="number">1</span> <span class="number">11</span> <span class="number">21</span> <span class="number">31</span> <span class="number">41</span> <span class="number">51</span> <span class="number">61</span> <span class="number">71</span> <span class="number">81</span> <span class="number">91</span>]</span><br><span class="line">[<span class="number">11</span> <span class="number">51</span> <span class="number">91</span>]</span><br></pre></td></tr></table></figure>


<h2 id="tf-reshape"><a href="#tf-reshape" class="headerlink" title="tf.reshape()"></a>tf.reshape()</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tf.reshape(</span><br><span class="line">    tensor,</span><br><span class="line">    shape,</span><br><span class="line">    name=<span class="literal">None</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>Given tensor, this operation returns a tensor that has the same values as tensor with shape shape.</p>
<p>If one component of shape is the special value -1, the size of that dimension is computed so that the total size remains constant. In particular, a shape of [-1] flattens into 1-D. At most one component of shape can be -1.　If shape is 1-D or higher, then the operation returns a tensor with shape shape filled with the values of tensor. In this case, the number of elements implied by shape must be the same as the number of elements in tensor.</p>
<p>demo</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">a = tf.constant(np.array(list(range(<span class="number">1</span>, <span class="number">9</span>+<span class="number">1</span>, <span class="number">1</span>))))</span><br><span class="line">b = tf.reshape(a, [<span class="number">3</span>, <span class="number">3</span>])</span><br><span class="line"><span class="comment"># t: a (3 x 2 x 3) tensor</span></span><br><span class="line">t = tf.constant(</span><br><span class="line">    [[[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>],</span><br><span class="line">      [<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>]],</span><br><span class="line">     [[<span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>],</span><br><span class="line">      [<span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>]],</span><br><span class="line">     [[<span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>],</span><br><span class="line">      [<span class="number">6</span>, <span class="number">6</span>, <span class="number">6</span>]]]</span><br><span class="line">)</span><br><span class="line">c = tf.reshape(t, [<span class="number">2</span>, <span class="number">-1</span>])</span><br><span class="line">d = tf.reshape(t, [<span class="number">-1</span>, <span class="number">9</span>])</span><br><span class="line">e = tf.reshape(t, [<span class="number">2</span>, <span class="number">-1</span>, <span class="number">3</span>])</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    print(sess.run(a), end=<span class="string">&#x27;\n\n&#x27;</span>)</span><br><span class="line">    print(sess.run(b), end=<span class="string">&#x27;\n\n&#x27;</span>)</span><br><span class="line">    print(b.get_shape().as_list())</span><br><span class="line">    print(sess.run(t), end=<span class="string">&#x27;\n\n&#x27;</span>)</span><br><span class="line">    print(t.get_shape().as_list())</span><br><span class="line">    print(sess.run(c), end=<span class="string">&#x27;\n\n&#x27;</span>)</span><br><span class="line">    print(c.get_shape().as_list())</span><br><span class="line">    print(sess.run(d), end=<span class="string">&#x27;\n\n&#x27;</span>)</span><br><span class="line">    print(d.get_shape().as_list())</span><br><span class="line">    print(sess.run(e), end=<span class="string">&#x27;\n\n&#x27;</span>)</span><br><span class="line">    print(e.get_shape().as_list())</span><br></pre></td></tr></table></figure>
<p>result</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">[[<span class="number">1</span> <span class="number">2</span> <span class="number">3</span>]</span><br><span class="line"> [<span class="number">4</span> <span class="number">5</span> <span class="number">6</span>]]</span><br><span class="line"></span><br><span class="line">[[<span class="number">1</span> <span class="number">4</span>]</span><br><span class="line"> [<span class="number">2</span> <span class="number">5</span>]</span><br><span class="line"> [<span class="number">3</span> <span class="number">6</span>]]</span><br><span class="line"></span><br><span class="line">[[<span class="number">1</span> <span class="number">4</span>]</span><br><span class="line"> [<span class="number">2</span> <span class="number">5</span>]</span><br><span class="line"> [<span class="number">3</span> <span class="number">6</span>]]</span><br><span class="line"></span><br><span class="line">[[[ <span class="number">1</span>  <span class="number">2</span>  <span class="number">3</span>]</span><br><span class="line">  [ <span class="number">4</span>  <span class="number">5</span>  <span class="number">6</span>]]</span><br><span class="line"></span><br><span class="line"> [[ <span class="number">7</span>  <span class="number">8</span>  <span class="number">9</span>]</span><br><span class="line">  [<span class="number">10</span> <span class="number">11</span> <span class="number">12</span>]]]</span><br><span class="line"></span><br><span class="line">[<span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>]</span><br><span class="line"></span><br><span class="line">[[[ <span class="number">1</span>  <span class="number">4</span>]</span><br><span class="line">  [ <span class="number">2</span>  <span class="number">5</span>]</span><br><span class="line">  [ <span class="number">3</span>  <span class="number">6</span>]]</span><br><span class="line"></span><br><span class="line"> [[ <span class="number">7</span> <span class="number">10</span>]</span><br><span class="line">  [ <span class="number">8</span> <span class="number">11</span>]</span><br><span class="line">  [ <span class="number">9</span> <span class="number">12</span>]]]</span><br><span class="line"></span><br><span class="line">[<span class="number">2</span>, <span class="number">3</span>, <span class="number">2</span>]</span><br></pre></td></tr></table></figure>

<h2 id="tf-split"><a href="#tf-split" class="headerlink" title="tf.split()"></a>tf.split()</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">tf.split(</span><br><span class="line">    value,</span><br><span class="line">    num_or_size_splits,</span><br><span class="line">    axis=<span class="number">0</span>,</span><br><span class="line">    num=<span class="literal">None</span>,</span><br><span class="line">    name=<span class="string">&#x27;split&#x27;</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>Splits a tensor into sub tensors.</p>
<p>If num_or_size_splits is an integer type, num_split, then splits value along dimension axis into num_split smaller tensors. Requires that num_split evenly divides value.shape[axis]. If num_or_size_splits is not an integer type, it is presumed to be a Tensor size_splits, then splits value into len(size_splits) pieces. The shape of the i-th piece has the same size as the value except along dimension axis where the size is size_splits[i].</p>
<p>demo</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">a = tf.constant(np.reshape(list(range(<span class="number">1</span>, <span class="number">6</span>+<span class="number">1</span>, <span class="number">1</span>)), (<span class="number">2</span>, <span class="number">3</span>)))</span><br><span class="line">b1, b2, b3 = tf.split(a, <span class="number">3</span>, axis=<span class="number">1</span>)</span><br><span class="line">d1, d2, d3 = tf.split(a, [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], axis=<span class="number">1</span>)</span><br><span class="line">c1, c2 = tf.split(a, [<span class="number">1</span>, <span class="number">2</span>], axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    print(sess.run(a), end=<span class="string">&#x27;\n\n&#x27;</span>)</span><br><span class="line">    print(sess.run(b1), end=<span class="string">&#x27;\n\n&#x27;</span>)</span><br><span class="line">    print(sess.run(b2), end=<span class="string">&#x27;\n\n&#x27;</span>)</span><br><span class="line">    print(sess.run(b3), end=<span class="string">&#x27;\n\n&#x27;</span>)</span><br><span class="line">    print(sess.run(d1), end=<span class="string">&#x27;\n\n&#x27;</span>)</span><br><span class="line">    print(sess.run(d2), end=<span class="string">&#x27;\n\n&#x27;</span>)</span><br><span class="line">    print(sess.run(d3), end=<span class="string">&#x27;\n\n&#x27;</span>)</span><br><span class="line">    print(sess.run(c1), end=<span class="string">&#x27;\n\n&#x27;</span>)</span><br><span class="line">    print(sess.run(c2), end=<span class="string">&#x27;\n\n&#x27;</span>)</span><br><span class="line">result</span><br><span class="line">[[<span class="number">1</span> <span class="number">2</span> <span class="number">3</span>]</span><br><span class="line"> [<span class="number">4</span> <span class="number">5</span> <span class="number">6</span>]]</span><br><span class="line"></span><br><span class="line">[[<span class="number">1</span>]</span><br><span class="line"> [<span class="number">4</span>]]</span><br><span class="line"></span><br><span class="line">[[<span class="number">2</span>]</span><br><span class="line"> [<span class="number">5</span>]]</span><br><span class="line"></span><br><span class="line">[[<span class="number">3</span>]</span><br><span class="line"> [<span class="number">6</span>]]</span><br><span class="line"></span><br><span class="line">[[<span class="number">1</span>]</span><br><span class="line"> [<span class="number">4</span>]]</span><br><span class="line"></span><br><span class="line">[[<span class="number">2</span>]</span><br><span class="line"> [<span class="number">5</span>]]</span><br><span class="line"></span><br><span class="line">[[<span class="number">3</span>]</span><br><span class="line"> [<span class="number">6</span>]]</span><br><span class="line"></span><br><span class="line">[[<span class="number">1</span>]</span><br><span class="line"> [<span class="number">4</span>]]</span><br><span class="line"></span><br><span class="line">[[<span class="number">2</span> <span class="number">3</span>]</span><br><span class="line"> [<span class="number">5</span> <span class="number">6</span>]]</span><br></pre></td></tr></table></figure>

<h2 id="tf-transpose"><a href="#tf-transpose" class="headerlink" title="tf.transpose()"></a>tf.transpose()</h2><p>demo</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">a = tf.constant(</span><br><span class="line">    [[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>],</span><br><span class="line">     [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]]</span><br><span class="line">)</span><br><span class="line">b = tf.transpose(a)</span><br><span class="line"><span class="comment"># equivaltently</span></span><br><span class="line">c = tf.transpose(a, [<span class="number">1</span>, <span class="number">0</span>])</span><br><span class="line"><span class="comment"># x : 2 x 2 x 3</span></span><br><span class="line">x = tf.constant(</span><br><span class="line">    [[[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>],</span><br><span class="line">      [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]],</span><br><span class="line">     [[<span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>],</span><br><span class="line">      [<span class="number">10</span>, <span class="number">11</span>, <span class="number">12</span>]]]</span><br><span class="line">)</span><br><span class="line"><span class="comment"># perm is more useful for n-dimensional tersors, for n &gt; 2</span></span><br><span class="line"><span class="comment"># y : 2 x 3 x 2</span></span><br><span class="line">y = tf.transpose(x, perm=[<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>])</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    print(sess.run(a), end=<span class="string">&#x27;\n\n&#x27;</span>)</span><br><span class="line">    print(sess.run(b), end=<span class="string">&#x27;\n\n&#x27;</span>)</span><br><span class="line">    print(sess.run(c), end=<span class="string">&#x27;\n\n&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    print(sess.run(x), end=<span class="string">&#x27;\n\n&#x27;</span>)</span><br><span class="line">    print(x.get_shape().as_list(), end=<span class="string">&#x27;\n\n&#x27;</span>)</span><br><span class="line">    print(sess.run(y), end=<span class="string">&#x27;\n\n&#x27;</span>)</span><br><span class="line">    print(y.get_shape().as_list(), end=<span class="string">&#x27;\n\n&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>result</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">[[<span class="number">1</span> <span class="number">2</span> <span class="number">3</span>]</span><br><span class="line"> [<span class="number">4</span> <span class="number">5</span> <span class="number">6</span>]]</span><br><span class="line"></span><br><span class="line">[[<span class="number">1</span> <span class="number">4</span>]</span><br><span class="line"> [<span class="number">2</span> <span class="number">5</span>]</span><br><span class="line"> [<span class="number">3</span> <span class="number">6</span>]]</span><br><span class="line"></span><br><span class="line">[[<span class="number">1</span> <span class="number">4</span>]</span><br><span class="line"> [<span class="number">2</span> <span class="number">5</span>]</span><br><span class="line"> [<span class="number">3</span> <span class="number">6</span>]]</span><br><span class="line"></span><br><span class="line">[[[ <span class="number">1</span>  <span class="number">2</span>  <span class="number">3</span>]</span><br><span class="line">  [ <span class="number">4</span>  <span class="number">5</span>  <span class="number">6</span>]]</span><br><span class="line"></span><br><span class="line"> [[ <span class="number">7</span>  <span class="number">8</span>  <span class="number">9</span>]</span><br><span class="line">  [<span class="number">10</span> <span class="number">11</span> <span class="number">12</span>]]]</span><br><span class="line"></span><br><span class="line">[<span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>]</span><br></pre></td></tr></table></figure>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2020/02/13/Tensorflow%20API/" data-id="ckjuw1zdv000ynbdl61lhbkvb" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-Graph Neural Network" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/02/03/Graph%20Neural%20Network/" class="article-date">
  <time datetime="2020-02-03T03:56:00.000Z" itemprop="datePublished">2020-02-03</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/RecSys-Machine-Learning/">RecSys & Machine Learning</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/02/03/Graph%20Neural%20Network/">Graph Neural Network</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
      	<!-- Table of Contents -->
		
        <hr>
<h2 id="GNN"><a href="#GNN" class="headerlink" title="GNN"></a>GNN</h2><p>Graph neural network/Graph embedding code.  </p>
<ul>
<li>GNN: gcn, graphSAGE</li>
<li>GE: node2vec</li>
</ul>
<h2 id="GCN"><a href="#GCN" class="headerlink" title="GCN"></a>GCN</h2><div align="center">
<img src="https://s3.ax1x.com/2020/11/15/DFYfqe.png" />
</div>

<p>GCN: learn a function of signals/features on a graph <em>G = (V, E)</em> which takes as input:  </p>
<ul>
<li>A feature description <em>x<sub>i</sub></em> for every node i summarized in a <em>N x D</em> feature matrix <em>X</em>. (<em>N</em> : number of nodes, <em>D</em> : number of input features)</li>
<li>A representative description of the graph structure in matrix form, eg: adjacency matrix <em>A</em>.</li>
</ul>
<p>and produces a node-level output <em>Z</em> (an <em>N x F</em> feature matrix, where <em>F</em> is the number of output features per node). Graph-level outputs can be modeled by producing some form of pooling operation.</p>
<p>Every neural network layer can then be written as a non-linear function, consider the following simple form of a layer-wise propagation rule:  </p>
<p><img src="http://latex.codecogs.com/png.latex?H%5E%7B(l+1)%7D=f%5Cleft(H%5E%7B(l)%7D,A%5Cright)=%5Csigma%5Cleft(AH%5E%7B(l)%7DW%5E%7B(l)%7D%5Cright)" alt="gnn">  </p>
<p>with <em>H<sup>(0)</sup>=X</em> and <em>H<sup>(L)</sup>=Z</em> (<em>z</em> for graph-level outputs), <em>L</em> being the number of layers. The specific models then differ only in how <img src="http://latex.codecogs.com/png.latex?f%5Cleft(%5Ccdot,%7B%5Ccdot%7D%5Cright)" alt="f(⋅,⋅)">  is chosen and parameterized.</p>
<h2 id="Preference"><a href="#Preference" class="headerlink" title="Preference"></a>Preference</h2><ul>
<li><p>Semi-Supervised Classification with Graph Convolutional Networks<br><a target="_blank" rel="noopener" href="https://github.com/tkipf/gcn/">https://github.com/tkipf/gcn/</a> </p>
</li>
<li><p>Inductive Representation Learning on Large Graphs<br><a target="_blank" rel="noopener" href="https://github.com/williamleif/graphsage-simple">https://github.com/williamleif/graphsage-simple</a></p>
</li>
<li><p>node2vec: Scalable Feature Learning for Networks<br><a target="_blank" rel="noopener" href="https://github.com/aditya-grover/node2vec">https://github.com/aditya-grover/node2vec</a></p>
</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2020/02/03/Graph%20Neural%20Network/" data-id="ckjuw1zdn000gnbdl29pyf8l8" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  


  <nav id="page-nav">
    
    <a class="extend prev" rel="prev" href="/">&amp;laquo; Prev</a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><a class="page-number" href="/page/4/">4</a><a class="extend next" rel="next" href="/page/3/">Next &amp;raquo;</a>
  </nav>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/About-Us/">About Us</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Always-Review/">Always Review</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Programming-Data/">Programming & Data</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Reading/">Reading</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/RecSys-Machine-Learning/">RecSys & Machine Learning</a></li></ul>
    </div>
  </div>


  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2099/01/">January 2099</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/12/">December 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/11/">November 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/10/">October 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/09/">September 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/08/">August 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/06/">June 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/04/">April 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/03/">March 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/02/">February 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/01/">January 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/12/">December 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/11/">November 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/10/">October 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/05/">May 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/12/">December 2018</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2099/01/01/About%20Us/">About Us</a>
          </li>
        
          <li>
            <a href="/2020/12/31/2020%20Annual%20Summary/">2020 Annual Summary</a>
          </li>
        
          <li>
            <a href="/2020/12/20/Shoe%20Dog/">Shoe Dog</a>
          </li>
        
          <li>
            <a href="/2020/12/16/Bert/">Bert</a>
          </li>
        
          <li>
            <a href="/2020/11/08/The%20Essence%20of%20RecSys/">The Essence of RecSys</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2021 Gold and Rabbit<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>




<script src="/js/script.js"></script>




  </div>
</body>
</html>